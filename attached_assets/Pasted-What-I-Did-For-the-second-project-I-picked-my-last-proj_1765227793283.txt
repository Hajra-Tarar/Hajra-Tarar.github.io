What I Did
For the second project, I picked my last project to see how far I’ve come at the end of this journey. This week’s theme was “magic,” and it took me the longest time to think of something that truly felt magical to me. I kept coming back to the idea of turning something internal into something visual. That led me to Colours of Self, a platform where you can visualize your memories and emotions as colours.
I believe we subconsciously associate colours with who we are — through our emotions, experiences, and memories. Each colour makes us feel a certain way, so I wanted to create a sense of magic through them. At the same time, I was curious to see how AI would interpret these subtleties and whether the colours it chose would match the ones I intuitively feel within.
Seeing the outcomes for the colour palettes and boards that AI would create for my self characteristics and memories, I became curious about testing how well it sees emotions in real time. This led me to the final feature, called emotion circle, for seeing how well it can read and translate my present emotions into colours. 
What I Learned
This project, which started as a challenge to test AI, ended up becoming a reflection on myself. At first, I wanted to expose the limitations of AI in understanding emotional nuances. The Emotion Circle did reveal some of these limits. While the AI could easily identify broad feelings like happiness or sadness, it missed more complex or subtle emotions, such as fear. That was interesting, but it wasn’t the part that stayed with me the most.
What I learned most about was my own expectations. In the process of trying to visualize my internal feelings, I found myself secretly wanting the AI to give me the colours I hoped to see.As if it might somehow read my thoughts, or understand me on a deeper level. And when I looked at the colours it generated for my emotions or personality, I started to interpret them as if the AI had real judgement or emotional awareness. It took me a while to realise that I was trying to find meaning in its outputs..meaning that wasn’t really there. I began to treat ot as something intentional, something that knew me ,

This made me think of the concern raised by Tarnoff of our tendency to expect understanding(even companionship) from technology. As he writes:
“Yet, as Eliza illustrated, it was surprisingly easy to trick people into feeling that a computer did know them – and into seeing that computer as human. Even in his original 1966 article, Weizenbaum had worried about the consequences of this phenomenon, warning that it might lead people to regard computers as possessing powers of “judgment” that are “deserving of credibility”. “A certain danger lurks there,” he wrote.” Tarnoff, B. (2023)
What began as a reflection on AI turned into a reflection on my own self-awareness. This tendency to project humanity onto machines shows how much we want to be understood, even by systems that cannot actually feel anything. Maybe Minsky was right when he said our self-awareness itself might be an illusion. Maybe what we really want is to feel in control, to be able to see inside our own minds, and AI becomes a false mirror we hope will show us something true. At the same time, it made me wonder whether AI, in a sense, reflects what we project onto it.
