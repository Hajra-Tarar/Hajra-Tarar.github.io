It’s been a few years since generative AI, especially ChatGPT, became a real part of everyday life. I still remember being in my sophomore year in CS and watching the shift unfold in real time. Suddenly everyone around me was debugging their code with AI, getting explanations for errors, or asking it to generate whole functions. I saw all of that, and yet I didn’t truly understand its scope. I didn’t predict how quickly it would outpace us and redefine our learning, our skills, and even our expectations.
Now, after completing six different projects (seven, if I include this one), I can say that even my highest expectations have been exceeded. The more I see what AI can achieve with so little input from us, the more impressed and the more uneasy I feel.
On one hand, I see the immense potential. I cannot deny that AI is incredibly helpful as a creative partner. It takes tasks I once thought were complex and turns them into simple prompts. It saves time, energy, and it feels “free.” Just type words on a screen and watch the work unfold. And I won’t deny that this has expanded opportunities for people who previously didn't have access to certain skills. Anyone can build a website. Anyone can code. That’s something worth acknowledging.
But when I take a step back and think beyond the convenience, I can’t ignore the environmental impact of AI. My mind keeps going back to a YouTube video I saw of a family living near a data center and what they were experiencing because of it. Those costs that are purposely hidden from our sights stay with me. They remind me that the “magic” comes from somewhere and that someone, somewhere, is paying that price.
But I still worry that there needs to be some form of control over how we use AI. When I look back just a few years, what truly unsettles me is not only the pace at which new AI technologies are being pushed out by these companies, but also how quickly we, the ordinary users, are becoming dependent on them. We talk about AI as a creative partner, but that dependency has already gone far beyond creativity. Some people use it as their academic partner, their search-engine partner and, most concerning of all, their emotional partner. And I can’t help but wonder where that leads us.
For the big companies, this loss of control on our end aligns perfectly with their incentives. But for us, the future feels even more unclear. Many of us have already begun to accept GPT responses as factual without knowing the sources, without understanding the inputs for such outputs, and without questioning what might be missing.
So I’m left asking myself: What lies ahead? Are we really the ones in control of this technology anymore, or is it slowly beginning to control us?
